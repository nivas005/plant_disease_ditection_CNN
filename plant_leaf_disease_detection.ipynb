{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1i_E0cW31PsYJf-whDNFSRCC_18z_Ky3N",
      "authorship_tag": "ABX9TyMkOh77vydeoVPBgFs7W8Yo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Seeding for reproducibility"
      ],
      "metadata": {
        "id": "cBIGK6ZL4Yn9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwP_KvUWHI-l"
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dependencies"
      ],
      "metadata": {
        "id": "vxptW3M24fp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "XNNp6EWHIKS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Curation\n",
        "\n",
        "Upload the kaggle.json file"
      ],
      "metadata": {
        "id": "ofcA_7Tu4i-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr7RIjRDIbm6",
        "outputId": "1a7b9f9f-84cb-4b6a-d00f-c60d7272bb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_credentails = json.load(open(\"kaggle.json\"))"
      ],
      "metadata": {
        "id": "epLEmuW3IkOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup Kaggle API key as environment variables\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentails[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentails[\"key\"]"
      ],
      "metadata": {
        "id": "cEDwL2snI6rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abdallahalidev/plantvillage-dataset"
      ],
      "metadata": {
        "id": "oo6NEvcQI9uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ls"
      ],
      "metadata": {
        "id": "3jRk-omoJ9MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded dataset\n",
        "with ZipFile(\"plantvillage-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "Yvin8QWvJ_2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"plantvillage dataset\"))\n",
        "\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/segmented\")))\n",
        "print(os.listdir(\"plantvillage dataset/segmented\")[:5])\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/color\")))\n",
        "print(os.listdir(\"plantvillage dataset/color\")[:5])\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/grayscale\")))\n",
        "print(os.listdir(\"plantvillage dataset/grayscale\")[:5])"
      ],
      "metadata": {
        "id": "_ai0IJg0KVrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/color/Grape___healthy\")))\n",
        "print(os.listdir(\"plantvillage dataset/color/Grape___healthy\")[:5])"
      ],
      "metadata": {
        "id": "-31ktdhGK4B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Path\n",
        "base_dir = 'plantvillage dataset/color'"
      ],
      "metadata": {
        "id": "1tPvYUCsLEVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
        "\n",
        "# Read the image\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "print(img.shape)\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Turn off axis numbers\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jfAggQBkLLic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
        "\n",
        "# Read the image\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "print(img)"
      ],
      "metadata": {
        "id": "jJb9eo6OL3Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Parameters\n",
        "img_size = 224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "CkCA9Y-8LoGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Data Generators\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Use 20% of data for validation\n",
        ")"
      ],
      "metadata": {
        "id": "gq3N-LrLLsUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Generator\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "HNYizFD2LyKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Generator\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "kcPwwJhZMVSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "D_NSoN3nMkI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "IdwCQ9guMniF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tno1CDlaN8z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-PjujFwwOhHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model training"
      ],
      "metadata": {
        "id": "2exqj10yOrPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
        "    epochs=7,  # Number of epochs\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
        ")"
      ],
      "metadata": {
        "id": "SqQ7W58yOjxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "print(\"Evaluating model...\")\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "eUwVQXVrT3LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GuqNcQzwUEM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "building a Predictive system"
      ],
      "metadata": {
        "id": "4Ixdq7CAUt5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Load and Preprocess the Image using Pillow\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    # Resize the image\n",
        "    img = img.resize(target_size)\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.array(img)\n",
        "    # Add batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Scale the image values to [0, 1]\n",
        "    img_array = img_array.astype('float32') / 255.\n",
        "    return img_array\n",
        "\n",
        "# Function to Predict the Class of an Image\n",
        "def predict_image_class(model, image_path, class_indices):\n",
        "    preprocessed_img = load_and_preprocess_image(image_path)\n",
        "    predictions = model.predict(preprocessed_img)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class_name = class_indices[predicted_class_index]\n",
        "    return predicted_class_name"
      ],
      "metadata": {
        "id": "7nxC5KNqU1vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from class indices to class names\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n"
      ],
      "metadata": {
        "id": "xfgG-wM-VAFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices"
      ],
      "metadata": {
        "id": "RPrx7neJVDlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the class names as json file\n",
        "json.dump(class_indices, open('class_indices.json', 'w'))\n"
      ],
      "metadata": {
        "id": "7l7IjBG0VJf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "image_path = '/content/plantvillage dataset/color/Apple___Black_rot/0090d05d-d797-4c99-abd4-3b9cb323a5fd___JR_FrgE.S 8727.JPG' # Using an image from the dataset\n",
        "\n",
        "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
        "\n",
        "# Output the result\n",
        "print(\"Predicted Class Name:\", predicted_class_name)"
      ],
      "metadata": {
        "id": "xEym3V-KYyZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('plant_disease_prediction_model.h5')"
      ],
      "metadata": {
        "id": "NjSg9ShUcWa0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}